{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Problem Definition\n\n> The goal of this project is to build an AI which will be able to recognize written digits accurately. ","metadata":{}},{"cell_type":"markdown","source":"## 2. Data\n\n>The data is taken from Kaggle's Digit Recognzier competition. It contains a dataset of images of  hand written numbers. The training data set, (train.csv), has 785 columns. The first column, called \"label\", is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n\n>For more information about the competiton check out the page for it [here](https://www.kaggle.com/competitions/digit-recognizer/data)","metadata":{}},{"cell_type":"markdown","source":"## 3. Evaluation\n>The evaluation metric for this contest is the categorization accuracy, or the proportion of test images that are correctly classified. For example, a categorization accuracy of 0.97 indicates that the AI classified all but 3% of the images.","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom IPython.display import display\n\nimport keras\nfrom keras import layers\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\ngen = image.ImageDataGenerator()\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow_hub as hub","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:15:55.264620Z","iopub.execute_input":"2024-01-05T19:15:55.264969Z","iopub.status.idle":"2024-01-05T19:16:00.147528Z","shell.execute_reply.started":"2024-01-05T19:15:55.264940Z","shell.execute_reply":"2024-01-05T19:16:00.146117Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Data Exploration","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\", index_col=0)\ntest = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\", index_col=0)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:00.155759Z","iopub.execute_input":"2024-01-05T19:16:00.156222Z","iopub.status.idle":"2024-01-05T19:16:05.698926Z","shell.execute_reply.started":"2024-01-05T19:16:00.156164Z","shell.execute_reply":"2024-01-05T19:16:05.697769Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":">First lets take a look at some of the sample images from the data set. Initially they are given as an array of integers so they will be converted back into grayscale images for us to view.","metadata":{}},{"cell_type":"code","source":"def get_image(df, row_index, width=28, height=28):\n    '''\n    This helper function allows the user to look at the images from the dataset look like.\n    Originally they are a data frame of numbers representing each pixel but this function creates\n    an image from these numbers which is shown to the user.\n    \n    df: Data frame\n    row_index: Row of dataframe\n    width: width of output image\n    height: height of output image\n    \n    returns: None\n    '''\n    \n    # Select the row based on the index\n    selected_row = df.iloc[row_index]\n\n    # Convert the selected row to a numpy array\n    pixel_values = selected_row.values.astype('uint8')\n\n    # Reshape the pixel values into an image\n    reshaped_array = pixel_values.reshape((height, width))\n\n    # Create an image from the array using Pillow\n    image = Image.fromarray(reshaped_array)\n    \n    display(image)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:05.700098Z","iopub.execute_input":"2024-01-05T19:16:05.700410Z","iopub.status.idle":"2024-01-05T19:16:05.707780Z","shell.execute_reply.started":"2024-01-05T19:16:05.700383Z","shell.execute_reply":"2024-01-05T19:16:05.706615Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"for i in range(10):\n    get_image(train, i)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:05.712507Z","iopub.execute_input":"2024-01-05T19:16:05.712976Z","iopub.status.idle":"2024-01-05T19:16:05.759804Z","shell.execute_reply.started":"2024-01-05T19:16:05.712932Z","shell.execute_reply":"2024-01-05T19:16:05.758700Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=L size=28x28>","image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAqklEQVR4nGNgGCRgz/84BgYGBgYWLHL7rf/9x6Wv+sff5Vw45AK+/73Ai0NO9vzf17445Mwu/v0bgUMu9t/fd6sEscuJX/r3dz4OfQIX//77EIhDUvrv33+4HCpy7t+/Y+w4JFf8/XsEl5zI6b8/fHDIie35+zUWhxxD+t+/+3HJRX74e1gShxz/nb9/A9AFmaC0vyIDAx8uyd//GP6q4rKS4dqteJxy9AQAbI49DkhoNMUAAAAASUVORK5CYII=\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=L size=28x28>","image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABEUlEQVR4nL2RvUoDURCFj2IhJDFR0S7401mIW2mjjYIGTBdcsLEWxMYn8BkSiFhaWCk2QsBKsNCwhRBIkweQaJWwixYq31osN7m7C5Y5zZ25350zwx1p9BobhjPZE23U/Ycw/SrnfgN0vi4WU6xwj1F3PZ+AJSwdx9nWIwCnlReA4CAGbwGvVltVptgEbmIz38HhThSf/0K7bME1oGiSCnApSRqXJC1J/o+Bz76JItiXvJ656jakvezAderdttU+MD2onJiPjf4Ws+1f6x8dAU3TptCCurWQ/CvgbUuS5q7gc8Eu3WwDT46zvOK0kj8kuQEAH9HhJtqeDZfSczMJmGsYFuymJ54sVwkJq7PJVY9Wf10bnse4xJV1AAAAAElFTkSuQmCC\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=L size=28x28>","image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAVklEQVR4nGNgGGDA3NvNjFOS898/DmQ+Ez6T0CWT8En6kW0sbsm/u/FI/lqAR5LFEo8dnP/+7SDPQTSSnIwmyYLMkWXEI8nwnwQ7UYD9v392RCumEQAAQVYOdaQtHWwAAAAASUVORK5CYII=\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=L size=28x28>","image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxUlEQVR4nGNgGJzgzmY2GJPTF11S5rsgjCl9CkPrp9lwyX/2MCYTlF5nAjcXLgZn3Nfnh7J+fsRQdQ4u8uYKhuRPJPt90SU//UVIhmI4995MViir4gMvuqTzbw0oK+6/K4bWVzugDOGvMEkmhCzMCx8uFXKh65x1loWBQcqj4fSFf/+a0SVt/zUW7vr6e6+3Rcc/T3RJ/hsvX87PMGFgYFCDSbIgrIS5luENjIHkIEyATfLzBUXckr/fmOKWZBM/hs8yigEAumQ3p/LGwk0AAAAASUVORK5CYII=\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=L size=28x28>","image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABBUlEQVR4nMXQMUoDQRiG4W+jQUGL2CgJJKJErAQvoY2oYJmgjUiEFILkBFaCHkAiglp6BysbK9Gg2SRFkIAEcgCzhe9ikc3sbnbT6tfM/PPMMP+M9J+x0mfXruve5BJRmy7h5TSiM6+YlEdx0Tfso4mQLdQA567d/gZgNYTnwNe2pM0WgF0MWLIOPEmSjj8B7KyPFaC/NZhnngEakwZdc9BoMoSHpkp3gbykmO9Q15G0PwZ1642xOCupOebOHSfSUGPZK5augLJl8AXgUpKUu+gB1YQkDTakHtcl6lXpYCUl6X2jF2hhj2De5kP9WUWfPgpTw9XhOHeyuybpvtN8+Il73l/lF0mJqOtQ2SOAAAAAAElFTkSuQmCC\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=L size=28x28>","image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/ElEQVR4nMXOvy+DURTG8W81rzYMRCMVA7nRSUxGiURYpIMB/4PEajCyiElspsaC1cBsKJFQFmlJLGXgjYSl9SM09dTwVod778yZnuRznpMD/zzxjYLyI34L9nS48/U27cV1bcGRXgc9Nvt5FcDui5ZcSxY1BmDCUruDy8rFAXpCGds6ShoCwKiFbb+4OJy7twstTHL7DcAKlQ9766J5lVMd2M105u4pSrHYuXO2cf0ePdbbeLQx0dkfha5uyjbWa80wmaqF9j9GlwBMVbRmG0Y3CWC0quM+B4O8ZiC1qpOMY7CgcnbzWQ9zHmOgKkn1eZ9BemL7bH/cb384P2pWU+wWjeO/AAAAAElFTkSuQmCC\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=L size=28x28>","image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAwUlEQVR4nGNgGDaAEUIFua1/w/BIhIuBgcEu4HrbIxQ1VX///P1z//PfP3///P3zUg4qygI1IPOwLYRlE8OwFFUjw+k0GGv73ysiMDYTlNaA0txyjO1vUDVqfobpNP6zhgsuDNUJV7yYcdc3uCTEQddNYXz1/xi+hQO7f381ETwmVEmN/+uu45S0ZdzAgFNS4/91nJLGRozIXBZUnahuRTOWEa/OGzcYcIEZf4NwyjG8/INbTvT/X9wO+v/vOgPRAADuzjoHqHl9DAAAAABJRU5ErkJggg==\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=L size=28x28>","image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABHklEQVR4nGNgGEqAEc4SzbVxYPiz9cZNhg1f/qCokUrb9e/fj3v3Hv779+/fv3MFLMiS5//921iqzsBg8SPNwCD9wL92ZMnofBUGBgYGBo8YBgYGBp4Hl1hxOMOo+8M/J6wy7JV3/n05xA/hwGzmSGZlYHguKesrtzPjwhs0Hb53//379+/fwwx1bP7kEmNgYEgKfZNzEYdTGBjY8p+vQ3eovhCcqfHkrDKKnNgrLQTH4sojNWTJhLnIPLnrezghLCYGBgYGho/Iko/qnayRuO6n+FFcdW06Eo/reRgTsuz+88i82B+N7Ahe6bsCFPfG/bjoyQNhak3+08GJIslgsOD6s3leDnEz7/+6lsmAAbgb97568P9QmzcbphzJAABNZl7rkEJ4DwAAAABJRU5ErkJggg==\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=L size=28x28>","image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABCUlEQVR4nGNgGGSAEYWnmcMu7s1wet32SxgKeSd//Pv339+/f/9+XcDAwMDAwIKQkz8oy7D9F+N/BgYGw/CPpb+Q9bEf/fd3KROEzZO2QwDF0Bl//y0SwuW01//m8eOS8/r1l5+BgUFARBhTjv34378MDJJNr/99n8iGLiny9+/GlNsf/v799/dvLbok68G/f//9/Xti9ux3f5+Ko8va/vz3cZocAwPD9X//rKBi8EA4rM38/REDAwPD//9vn+JytebHv9txyTGc/Ps3DZdc0b+/s1hxyNn9+/9RDrsUV9nrvz/TsUiYBzKkXf779287Nl3+n1/9+/v3RilWIw2+/v13vk4al0OpCQAFFmtfdKk7ngAAAABJRU5ErkJggg==\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<PIL.Image.Image image mode=L size=28x28>","image/png":"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgoD9ghNKs5j4M3NmMJ1Ys/v4dXY3kjL8wUIMQZYFQeZ7fOc/+e/veRJUhXDoTXavcVD9mBgYGkba/fx/gcoLMOWRJJlRJI31kHqokq+hbXGby9d25/ebv3w+V7FgkJf7+/fv39cu/f3eaYkpyTDt06JCpRuLfv6sgAixIkj+yGBgYGBiCcFnLwMBg/haukwlD0lsAlzYWnoqDf/9ek8Emxz7z79+/f6/IoYoqdrixMUg77/r79+/fV/KoclLP//7dv/3+379//665UYBmnMp1eHTqS6LbxRp+/+/fv19m3L+fi+xxaDJxfl/3ZNehDzwMX3D5g14AAOtVbvmpYSLSAAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"cell_type":"markdown","source":">Now lets get a good idea of the properties of the data frames","metadata":{}},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:05.760999Z","iopub.execute_input":"2024-01-05T19:16:05.761543Z","iopub.status.idle":"2024-01-05T19:16:05.768873Z","shell.execute_reply.started":"2024-01-05T19:16:05.761513Z","shell.execute_reply":"2024-01-05T19:16:05.767820Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"((42000, 784), (28000, 783))"},"metadata":{}}]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:05.770059Z","iopub.execute_input":"2024-01-05T19:16:05.770457Z","iopub.status.idle":"2024-01-05T19:16:05.798761Z","shell.execute_reply.started":"2024-01-05T19:16:05.770412Z","shell.execute_reply":"2024-01-05T19:16:05.797538Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\nlabel                                                                           \n1           0       0       0       0       0       0       0       0       0   \n0           0       0       0       0       0       0       0       0       0   \n1           0       0       0       0       0       0       0       0       0   \n4           0       0       0       0       0       0       0       0       0   \n0           0       0       0       0       0       0       0       0       0   \n\n       pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\nlabel          ...                                                     \n1           0  ...         0         0         0         0         0   \n0           0  ...         0         0         0         0         0   \n1           0  ...         0         0         0         0         0   \n4           0  ...         0         0         0         0         0   \n0           0  ...         0         0         0         0         0   \n\n       pixel779  pixel780  pixel781  pixel782  pixel783  \nlabel                                                    \n1             0         0         0         0         0  \n0             0         0         0         0         0  \n1             0         0         0         0         0  \n4             0         0         0         0         0  \n0             0         0         0         0         0  \n\n[5 rows x 784 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 784 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Check if \"label\" is the index of the DataFrame\nis_label_index = 'label' in train.index.names\n\nif is_label_index:\n    print(\"'label' is part of the index.\")\nelse:\n    print(\"'label' is not part of the index.\")","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:05.800002Z","iopub.execute_input":"2024-01-05T19:16:05.800408Z","iopub.status.idle":"2024-01-05T19:16:05.807360Z","shell.execute_reply.started":"2024-01-05T19:16:05.800340Z","shell.execute_reply":"2024-01-05T19:16:05.806229Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"'label' is part of the index.\n","output_type":"stream"}]},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:05.808845Z","iopub.execute_input":"2024-01-05T19:16:05.809205Z","iopub.status.idle":"2024-01-05T19:16:05.822873Z","shell.execute_reply.started":"2024-01-05T19:16:05.809176Z","shell.execute_reply":"2024-01-05T19:16:05.821718Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"pixel0      int64\npixel1      int64\npixel2      int64\npixel3      int64\npixel4      int64\n            ...  \npixel779    int64\npixel780    int64\npixel781    int64\npixel782    int64\npixel783    int64\nLength: 784, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:05.824801Z","iopub.execute_input":"2024-01-05T19:16:05.825525Z","iopub.status.idle":"2024-01-05T19:16:05.832563Z","shell.execute_reply.started":"2024-01-05T19:16:05.825483Z","shell.execute_reply":"2024-01-05T19:16:05.831389Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(42000, 784)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Preprocessing Data\n>In order to prepare these images for a model I will change pixel values from int64 to float32. Each image is 28x28 which can be kept. The training and data sets will also be batched","metadata":{}},{"cell_type":"code","source":"train = train.astype(\"float32\")\ntest = test.astype(\"float32\")","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:05.834034Z","iopub.execute_input":"2024-01-05T19:16:05.835062Z","iopub.status.idle":"2024-01-05T19:16:05.948207Z","shell.execute_reply.started":"2024-01-05T19:16:05.835021Z","shell.execute_reply":"2024-01-05T19:16:05.947109Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Normalize data\ntrain = train / 255.0\ntest = test / 255.0","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:05.949995Z","iopub.execute_input":"2024-01-05T19:16:05.950758Z","iopub.status.idle":"2024-01-05T19:16:06.048449Z","shell.execute_reply.started":"2024-01-05T19:16:05.950716Z","shell.execute_reply":"2024-01-05T19:16:06.047479Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Extracting the index as labels and resetting the index\ny = train.index.values  # Extracting the index as labels\nX = train.reset_index(drop=True).values  # Resetting the index and using remaining columns as features","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:06.049388Z","iopub.execute_input":"2024-01-05T19:16:06.049695Z","iopub.status.idle":"2024-01-05T19:16:06.156559Z","shell.execute_reply.started":"2024-01-05T19:16:06.049669Z","shell.execute_reply":"2024-01-05T19:16:06.155381Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and validation sets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Reshape the training and validation data after splitting\nX_train = X_train.reshape(-1, 28, 28, 1)\nX_valid = X_valid.reshape(-1, 28, 28, 1)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:06.160852Z","iopub.execute_input":"2024-01-05T19:16:06.161235Z","iopub.status.idle":"2024-01-05T19:16:06.567026Z","shell.execute_reply.started":"2024-01-05T19:16:06.161202Z","shell.execute_reply":"2024-01-05T19:16:06.565907Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"test.reset_index(inplace=True)\ntest.columns","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:06.568430Z","iopub.execute_input":"2024-01-05T19:16:06.568742Z","iopub.status.idle":"2024-01-05T19:16:06.578993Z","shell.execute_reply.started":"2024-01-05T19:16:06.568715Z","shell.execute_reply":"2024-01-05T19:16:06.577837Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Index(['pixel0', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n       'pixel7', 'pixel8', 'pixel9',\n       ...\n       'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779',\n       'pixel780', 'pixel781', 'pixel782', 'pixel783'],\n      dtype='object', length=784)"},"metadata":{}}]},{"cell_type":"code","source":"# Convert the DataFrame to a NumPy array\ntest_array = test.values\n\n# Reshape the array with the index as the first column\ntest_array = test_array.reshape(-1, 28, 28, 1)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:06.580393Z","iopub.execute_input":"2024-01-05T19:16:06.580800Z","iopub.status.idle":"2024-01-05T19:16:06.659924Z","shell.execute_reply.started":"2024-01-05T19:16:06.580769Z","shell.execute_reply":"2024-01-05T19:16:06.658697Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_array.shape","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:06.661433Z","iopub.execute_input":"2024-01-05T19:16:06.661792Z","iopub.status.idle":"2024-01-05T19:16:06.669002Z","shell.execute_reply.started":"2024-01-05T19:16:06.661761Z","shell.execute_reply":"2024-01-05T19:16:06.667916Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(28000, 28, 28, 1)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Building a model","metadata":{}},{"cell_type":"code","source":"# Define a simple CNN architecture\n# Example model architecture\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\n    tf.keras.layers.Dense(300, activation=\"relu\"),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:06.670701Z","iopub.execute_input":"2024-01-05T19:16:06.671489Z","iopub.status.idle":"2024-01-05T19:16:06.778817Z","shell.execute_reply.started":"2024-01-05T19:16:06.671455Z","shell.execute_reply":"2024-01-05T19:16:06.777559Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:06.780117Z","iopub.execute_input":"2024-01-05T19:16:06.780498Z","iopub.status.idle":"2024-01-05T19:16:06.802811Z","shell.execute_reply.started":"2024-01-05T19:16:06.780464Z","shell.execute_reply":"2024-01-05T19:16:06.801131Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"#Callback functions\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\ncheckpoint = ModelCheckpoint('best_model.h5', save_best_only=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)\n\n\n# Train the model\nhistory = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2, callbacks=[early_stopping, \n                                                                                                 checkpoint,\n                                                                                                 reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:16:06.804697Z","iopub.execute_input":"2024-01-05T19:16:06.805282Z","iopub.status.idle":"2024-01-05T19:16:27.931644Z","shell.execute_reply.started":"2024-01-05T19:16:06.805238Z","shell.execute_reply":"2024-01-05T19:16:27.930373Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/5\n840/840 [==============================] - 5s 5ms/step - loss: 0.2856 - accuracy: 0.9145 - val_loss: 0.1446 - val_accuracy: 0.9585 - lr: 0.0010\nEpoch 2/5\n 40/840 [>.............................] - ETA: 3s - loss: 0.1093 - accuracy: 0.9664","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"840/840 [==============================] - 4s 4ms/step - loss: 0.1113 - accuracy: 0.9667 - val_loss: 0.1213 - val_accuracy: 0.9659 - lr: 0.0010\nEpoch 3/5\n840/840 [==============================] - 4s 5ms/step - loss: 0.0694 - accuracy: 0.9782 - val_loss: 0.1158 - val_accuracy: 0.9667 - lr: 0.0010\nEpoch 4/5\n840/840 [==============================] - 4s 5ms/step - loss: 0.0522 - accuracy: 0.9828 - val_loss: 0.1289 - val_accuracy: 0.9613 - lr: 0.0010\nEpoch 5/5\n840/840 [==============================] - 4s 5ms/step - loss: 0.0372 - accuracy: 0.9879 - val_loss: 0.1149 - val_accuracy: 0.9702 - lr: 0.0010\n","output_type":"stream"}]},{"cell_type":"code","source":"# Predict on the test data\npredictions = model.predict(test_array)\n\n# Get the predicted digit for each image\npredicted_digits = np.argmax(predictions, axis=1)  # Assuming predictions are one-hot encoded\n\n# Create a DataFrame with ImageId and predicted digit\nimage_ids = np.arange(1, len(predicted_digits) + 1)  # ImageIds start from 1\nsubmission_df = pd.DataFrame({'ImageId': image_ids, 'Label': predicted_digits})\n\n# Save predictions to a CSV file in the required format\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-05T19:21:31.259127Z","iopub.execute_input":"2024-01-05T19:21:31.259607Z","iopub.status.idle":"2024-01-05T19:21:33.521347Z","shell.execute_reply.started":"2024-01-05T19:21:31.259569Z","shell.execute_reply":"2024-01-05T19:21:33.520269Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"875/875 [==============================] - 2s 2ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Results\n\n>The submissions received an accuracy of 96.971%!! Not bad!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}